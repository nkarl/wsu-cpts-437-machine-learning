---

kanban-plugin: basic

---

## Backlog

- [ ] **Skim through the chapters**
- [ ] **Revise and reinforce the simple topics**
- [ ] **Revise and reinforce the advanced topics**
- [ ] **Simple** topics<br>- [ ] decision trees<br>	- [ ] *optim.*: tree pruning<br>	- [ ] *optim.*: depth limiting<br>- [ ] Bayes Optimal Classifier<br>- [ ] Geometric<br>	- [ ] Nearest Neighbors<br>	- [ ] KNN<br>- [ ] Perceptron<br>- [ ] Naive Bayes


## TODO

- [ ] **ReRead Perceptron**<br>- [ ] Take note of important constructs<br>	- [ ] loss function (convex)<br>	- [ ] bias & variance<br>	- [ ] weight vector<br>	- [ ] regularizer (to prevent overfitting)<br>	- [ ] activation function (sigmoid)
- [ ] **Advanced** topics<br>- [ ] Neural Networks<br>	- [ ] Back-Propagation<br>- [ ] Deep Neural Networks<br>	- [ ] RNN (Recurrent)<br>	- [ ] AutoEncoders (AE)<br>		- [ ] VAE (Variational)<br>	- [ ] GAN<br>	- [ ] CNN (Convolutional)
- [ ] *Neural Networks*<br>- [ ] gradient descent<br>- [ ] back-propagation
- [ ] **Linear** Models & Optimization Strategies<br>- [ ] weight regularization<br>- [ ] gradient descent<br>- [ ] sub-gradients<br>- [ ] **closed-formed optimization** for *squared loss* (linear regression)


## DONE

- [ ] - [x] List major topics and solution approaches
- [ ] - [x] List major ML algorithms
- [ ] - [x] Organize the notes in Obsidian
- [ ] Group the major topics<br><br>- [x] Finish parsing out the fundamental concepts (in chapter 2 ACIM)<br>	- [x] inductive bias<br>	- [x] variance & bias<br>	- [x] Underfitting & Overfitting<br>- [x] Put the fundamentals in Overview
- [ ] - [x] Map out week progression and major concepts
- [ ] - [x] Work out framework for each chapter


## CNN





%% kanban:settings
```
{"kanban-plugin":"basic"}
```
%%